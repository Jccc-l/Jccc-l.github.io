---
title: 毕业设计大模型智能助手
mathjax: false
katex: false
date: 2024-11-13 11:24:02
description: 毕业设计头疼中
categories: 人工智能
tags:
- LLM
- Python
- 数据库
---

# 毕业设计大模型智能助手

## 前置准备

安装Docker

```sh
$ sudo pacman -S docker
```

将用户添加指docker组

```sh
$ sudo usermod -aG docker 用户名
```

编辑文件，配置Docker镜像（可以继续添加其他镜像，用逗号分隔）

```json /etc/daemon.json
{
    "registry-mirrors":
    [    
        "https://dockerproxy.net"
    ]
}
```

## 数据存储和预处理

实验使用的的数据集来源于Stack Overflow的贴子[^1]

[磁力链接](magnet:?xt=urn:btih:745b43ba30154eb2bc1df080b4c12de904edb2cb&dn=Stack%20Exchange%20Data%20Dump%20September%202024&tr=udp%3A%2F%2Ftracker.opentrackr.org%3A1337%2Fannounce&ws=https%3A%2F%2Farchive.org%2Fdownload%2F)

[^1]: [stackexchange_20240930](https://communitydatadump.com/index.html)

## 安装配置数据库

计划将文本数据存储在MySQL数据库中

使用Docker安装MySQL数据库

```sh
$ export STORAGE_LOCATION=$HOME/Documents/docker/mysql&& \
mkdir -p "$STORAGE_LOCATION/etc/my.cnf.d" && \
mkdir -p "$STORAGE_LOCATION/etc/mysql" && \
mkdir -p "$STORAGE_LOCATION/var/lib/mysql" && \
mkdir -p "$STORAGE_LOCATION/var/log" && \
touch "$STORAGE_LOCATION/etc/my.cnf" && \
touch "$STORAGE_LOCATION/var/log/mysqld.log"

docker run -d \
--name mysql-container \
-p 3306:3306 \
-e TZ=Asia/Shanghai \
-e MYSQL_ROOT_PASSWORD=123 \
-v $STORAGE_LOCATION/etc/my.cnf.d:/etc/my.cnf.d \
-v $STORAGE_LOCATION/etc/mysql:/etc/mysql \
-v $STORAGE_LOCATION/var/lib/mysql:/var/lib/mysql \
-v $STORAGE_LOCATION/etc/my.cnf:/etc/my.cnf \
-v $STORAGE_LOCATION/var/log/mysqld.log:/var/log/mysqld.log \
mysql
```

命令解释
> - `docker run -d`
>     - 在后台运行容器
> - `--name mysql-container`
>     - 把容器命令为mysql-container
> - `-p 3306:3306`
>     - 把主机的3306端口映射到容器而3306端口
> - `-e TZ=Asia/Shanghai`
>     - 设置时区`timezone`环境变量
> - `-e MYSQL_ROOT_PASSWORD=123`
>     - 设置MySQL数据库的`root`用户密码
> - `mysql`
>     - 使用`mysql`镜像构建容器

<!--
> - `-e MYSQL_USER=jccc`
>     - 创建一个名为`jccc`的用户
> - `-e MYSQL_PASSWORD=123`
>     - 设置MySQL数据库的新用户密码
-->

##  导入数据

我要使用到的数据文件是Posts.xml

通过Python脚本导入数据

## Ollama安装配置

Ollama现在支持通过Docker构建[^2]

[^2]: [Ollama is now available as an official Docker image](https://ollama.com/blog/ollama-is-now-available-as-an-official-docker-image)

### 构建Ollama的Docker容器

拉取Ollama镜像

```sh
$ docker pull ollama/ollama
```

创建并启动容器（支持显卡或CPU）

#### CPU

```sh
$ docker run -d -v $HOME/Documents/docker/ollama:/root/.ollama -p 11434:11434 --name ollama ollama/ollama
```

#### NVIDIA GPU

NVIDIA GPU需要先安装工具包，Arch的安装命令如下，其他系统参考说明文档[^3]

[^3]: [Installing the NVIDIA Container Toolkit](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html#installation)

```sh
$ sudo pacman -S nvidia-container-toolkit
```

安装完工具包，需要重启一下Docker

```sh
$ sudo systemctl restart docker
```

然后启动容器，以下这条命令做了以下操作
- 把所有GPU分配给容器
- 把宿主机的`$HOME/Documents/docker/ollama`目录挂载到容器的`/root/.ollama`目录中
- 将容器命名为`ollama`
- 把主机的11434端口映射到容器的11434端口

```sh
$ docker run -d --gpus=all -v $HOME/Documents/docker/ollama:/root/.ollama -p 11434:11434 --name ollama ollama/ollama
```

### 运行模型

这里先介绍以下如何在Docker中执行命令，通常是使用`docker exec`命令， 这个命令的第一个参数是容器名称，第二个参数是要运行的命令，例子如下：
- 通过命令`docker exec -it ollama bash`，在名为ollama的容器中执行`bash`命令，进入ollama容器的bash命令行交互界面
- 通过命令`docker exec -it ollama ollama ...`，在名为ollama的容器中执行`ollama`命令


Ollama有以下常用命令[^4]

[^4]: [Ollama Github Repository](https://github.com/ollama/ollama)

拉取模型，镜像详情可以在Ollama仓库中查询[^5]

[^5]: [Ollama Models](https://ollama.com/library)

```sh
$ ollama pull qwen:4b
```

根据Modefile文件创建模型

```sh
$ ollama create mymodel -f ./Modelfile
```

移除模型

```sh
$ ollama rm llama3.2
```

复制模型

```sh
$ ollama cp llama3.2 mymodel
```

## Open Webui安装配置

Ollama主要作为一个后端服务来运行，通常需要一个前端用户界面结合使用，而Open WebUI是一个功能丰富且用户友好的Web界面，支持多重语言模型运行器，提供一个图形化的用户界面来管理和使用语言模型[^6]

Open WebUI可以对模型的各种参数进行调整

[^6]: [Open WebUI Github Repository](https://github.com/open-webui/open-webui)

同样使用Docker容器进行安装

拉取镜像

```sh
$ docker pull ghcr.io/open-webui/open-webui:main
```

可以通过以下命令运行

```sh
$ docker run -d -p 3000:8080 \
--add-host=host.docker.internal:host-gateway \
-v $HOME/Documents/docker/open-webui:/app/backend/data \
--name open-webui \
--restart always \
ghcr.io/open-webui/open-webui:main
```

> 命令解释
> - `docker run`
>     - 这是启动一个新的Docker容器的命令。
> - `-d`
>     - 表示容器将以分离模式（后台）运行。这意味着容器会在后台运行，不会占用当前终端。
> - `-p 3000:8080`
>     - 指定端口映射，将宿主机的3000端口映射到容器内的8080端口。这样可以从宿主机通过3000端口访问容器内的服务。
> - `--add-host=host.docker.internal`host-gateway:
>     - 这个选项将宿主机的IP地址添加到容器的 /etc/hosts 文件中，使用别名 host.docker.internal。这使得容器可以通过 host.docker.internal 访问宿主机上的服务。这对于开发和调试非常有用。
> - `-v $HOME/Documents/docker/open-webui`/app/backend/data:
>     - 这个选项使用绑定挂载（bind mount）将宿主机上的 $HOME/Documents/docker/open-webui 目录挂载到容器内的 /app/backend/data 目录。这样容器内的应用程序可以读写宿主机上的这个目录，适用于需要直接访问宿主机文件的情况。
> - `--name open-webui`
>     - 为容器指定一个名称 open-webui。这使得后续操作（如停止、删除等）更加方便。
> - `--restart always`
>     - 设置容器的重启策略为 always，这意味着无论容器因何原因停止（包括手动停止），Docker 都会自动重启容器。这对于需要长期运行的服务非常有用。
> - `ghcr.io/open-webui/open-webui:main`
>     - 这是将要运行的Docker镜像的名称和标签。ghcr.io 是 GitHub Container Registry 的域名，open-webui/open-webui 是仓库和镜像名称，main 是标签，表示这个镜像是基于 main 分支构建的版本。

如果想支持显卡，可以使用以下命令
> **由于网络原因，部分软件库无法下载，无法支持显卡**

```sh
$ docker run -d -p 3000:8080 \
--gpus all \
--add-host=host.docker.internal:host-gateway \
-v $HOME/Documents/docker/open-webui:/app/backend/data \
--name open-webui \
--restart always \
ghcr.io/open-webui/open-webui:cuda
```

> 命令解释
> - `docker run -d -p 3000:8080`
>     - `docker run`启动一个新的Docker容器
>     - `-d`表示容器将以分离模式运行，即后台运行
>     - `-p 3000:8080`指定端口映射，将宿主机的3000端口映射到容器内的8080端口，允许外部访问容器内的服务。
> - `--gpus all`
>     - 这个选项用于启用GPU支持，并将所有可用的GPU设备分配给容器。
> - `--add-host=host.docker.internal:host-gateway`
>     - 这个选项将宿主机的IP地址添加到容器的`/etc/hosts`文件中，使用别名`host.docker.internal`。这使得容器可以通过`host.docker.internal`访问宿主机上的服务。
> - `-v $HOME/Documents/docker/open-webui:/app/backend/data`
>     - 使用绑定挂载（bind mount）将宿主机上的`$HOME/Documents/docker/open-webui`目录挂载到容器内的`/app/backend/data`目录。这样容器内的应用程序可以读写宿主机上的这个目录。
> - `--name open-webui`
>     - 为容器指定一个名称`open-webui`
> - `--restart always`:
>     - 设置容器的重启策略为`always`，这意味着无论容器因何原因停止（包括手动停止），Docker 都会自动重启容器。
> - `ghcr.io/open-webui/open-webui:cuda`
>     - 这是将要运行的Docker镜像的名称和标签。`ghcr.io`是GitHub Container Registry的域名，`open-webui/open-webui`是仓库和镜像名称，`cuda`是标签，表示这个镜像是针对CUDA（NVIDIA的GPU计算平台）优化的版本。

## Anything LLM安装配置

Anything LLM有多种安装方式，我这里通过Docker进行安装[^7]

[^7]: [How to use Dockerized Anything LLM](https://docs.anythingllm.com/installation-docker/local-docker)

拉取镜像

```sh
$ docker pull mintplexlabs/anythingllm
```

启动一个新镜像

```sh
$ export STORAGE_LOCATION=$HOME/Documents/docker/anythingllm && \
mkdir -p $STORAGE_LOCATION && \
touch "$STORAGE_LOCATION/.env" && \
docker run -d -p 3001:3001 \
--cap-add SYS_ADMIN \
-v ${STORAGE_LOCATION}:/app/server/storage \
-v ${STORAGE_LOCATION}/.env:/app/server/.env \
-e STORAGE_DIR="/app/server/storage" \
--name anythingllm \
mintplexlabs/anythingllm
```

> 命令解释
> 
> 前置命令
> - `export STORAGE_LOCATION=$HOME/Documents/docker/anythingllm`
>     - 这是一个bash命令，用于在当前shell会话中设置一个环境变量`STORAGE_LOCATION`，其值为用户主目录下的`Documents/docker/anythingllm`文件夹。这个变量将在后续的Docker命令中使用。
> - `mkdir -p $STORAGE_LOCATION`
>     - 这也是一个bash命令，它创建了由`STORAGE_LOCATION`变量指定的目录（如果该目录不存在的话）。`-p`选项确保即使父目录不存在也会被创建。
> - `touch "$STORAGE_LOCATION/.env"`
>     - `touch`命令用于创建一个空文件或更新现有文件的时间戳。这里是在`STORAGE_LOCATION`目录下创建了一个`.env`文件，这个文件通常用来存储环境变量。
> 
> Docker 命令
> 
> - `docker run`
>     - 这是启动一个新的Docker容器的命令。
> - `-d`
>     - 表示容器将以分离模式（后台）运行。这意味着容器会在后台运行，不会占用当前终端。
> - `-p 3001:3001`
>     - 指定端口映射，将宿主机的3001端口映射到容器内的3001端口。这样可以从宿主机通过3001端口访问容器内的服务。
> - `--cap-add SYS_ADMIN`
>     - 这个选项给容器添加了`SYS_ADMIN`能力，这是一个Linux内核的能力，赋予了容器更多的权限，比如执行某些系统管理任务。请注意，赋予额外的能力可能会增加安全风险。
> - `-v ${STORAGE_LOCATION}:/app/server/storage`
>     - 这个选项使用绑定挂载（bind mount）将宿主机上的`${STORAGE_LOCATION}`目录挂载到容器内的`/app/server/storage`目录。这样容器内的应用程序可以读写宿主机上的这个目录，适用于需要直接访问宿主机文件的情况。
> - `-v ${STORAGE_LOCATION}/.env:/app/server/.env`
>     - 这个选项使用绑定挂载将宿主机上的`${STORAGE_LOCATION}/.env`文件挂载到容器内的`/app/server/.env`文件。这样容器内的应用程序可以读取这些环境配置。
> - `-e STORAGE_DIR="/app/server/storage"`
>     - 这个选项向容器传递环境变量`STORAGE_DIR`，其值为`/app/server/storage`。应用程序内部用于引用存储目录的位置。
> - `--name anythingllm`
>     - 将容器命名为anythingllm
> - `mintplexlabs/anythingllm`
>     - 这是将要运行的Docker镜像的名称。Docker会从Docker Hub或其他注册表拉取这个镜像（如果本地没有的话），并基于此镜像启动一个新的容器。

## 向量数据库Milvus

进入到你需要存储milvus数据的目录（脚本会把容器的目录挂载的当前目录下）

```sh
$ cd $HOME/Documents/docker/milvus
```

下载安装脚本

```sh
$ curl -sfL https://raw.githubusercontent.com/milvus-io/milvus/master/scripts/standalone_embed.sh -o standalone_embed.sh
```

启动Docker容器

```sh
$ bash standalone_embed.sh start
```

为了方便数据库的管理，需要用到Milvus_CLI工具[^8]

通过Docker安装

```sh
$ docker run -it zilliz/milvus_cli:latest
```

[^8]: [Milvus Command-Line Interface](https://milvus.io/docs/cli_overview.md)
